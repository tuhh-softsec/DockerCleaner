{"seed":3903746558,"processedDockerfileHash":"a4a221ad6edf37294969f88ca4de1ade","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-apt-get","have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM debian:stretch\nMAINTAINER Jim Harner <ejharner@gmail.com>\nARG hadoopversion=2.9.1\nARG sparkversion=2.4.3\nARG hiveversion=2.1.1\nRUN apt-get update \\\n && apt-get install --no-install-recommends locales=2.24-11+deb9u4 -y \\\n && dpkg-reconfigure -f noninteractive locales \\\n && locale-gen C.UTF-8 \\\n && /usr/sbin/update-locale LANG=C.UTF-8 \\\n && echo \"en_US.UTF-8 UTF-8\" >> /etc/locale.gen \\\n && locale-gen \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   Users with other locales should set this in their derivative image\nENV LANG=\"en_US.UTF-8\"\nENV LANGUAGE=\"en_US:en\"\nENV LC_ALL=\"en_US.UTF-8\"\nRUN apt-get update \\\n && apt-get install --no-install-recommends curl=7.52.1-5+deb9u16 unzip=6.0-21+deb9u2 python3=3.5.3-1 python3-setuptools=33.1.1-1 -y \\\n && ln -s /usr/bin/python3 /usr/bin/python \\\n && easy_install3 pip py4j \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   http://blog.stuart.axelbrooke.com/python-3-on-spark-return-of-the-pythonhashseed\nENV PYTHONHASHSEED=\"0\"\nENV PYTHONIOENCODING=\"UTF-8\"\nENV PIP_DISABLE_PIP_VERSION_CHECK=\"1\"\n#   JAVA\nARG JAVA_MAJOR_VERSION=8\nARG JAVA_UPDATE_VERSION=131\nARG JAVA_BUILD_NUMBER=11\nENV JAVA_HOME=\"/usr/jdk1.${JAVA_MAJOR_VERSION}.0_${JAVA_UPDATE_VERSION}\"\nENV PATH=\"$PATH:$JAVA_HOME/bin\"\nRUN curl -sL --retry 3 --insecure --header \"Cookie: oraclelicense=accept-securebackup-cookie;\" \"http://download.oracle.com/otn-pub/java/jdk/${JAVA_MAJOR_VERSION}u${JAVA_UPDATE_VERSION}-b${JAVA_BUILD_NUMBER}/d54c1d3a095b4ff2b6607d096fa80163/server-jre-${JAVA_MAJOR_VERSION}u${JAVA_UPDATE_VERSION}-linux-x64.tar.gz\" | gunzip | tar x -C /usr/ \\\n && ln -s $JAVA_HOME /usr/java \\\n && rm -rf $JAVA_HOME/man\n#  ###################\n#   HADOOP\n#  ###################\nENV HADOOP_VERSION=\"2.9.1\"\nENV HADOOP_HOME=\"/usr/hadoop-$HADOOP_VERSION\"\nENV HADOOP_CONF_DIR=\"$HADOOP_HOME/etc/hadoop\"\nENV PATH=\"$PATH:$HADOOP_HOME/bin\"\nRUN curl -sL --retry 3 \"http://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz\" | gunzip | tar -x -C /usr/ \\\n && rm -rf $HADOOP_HOME/share/doc \\\n && chown -R root:root $HADOOP_HOME\n#   SPARK\nENV SPARK_VERSION=\"2.4.3\"\nENV SPARK_PACKAGE=\"spark-${SPARK_VERSION}-bin-without-hadoop\"\nENV SPARK_HOME=\"/usr/spark-${SPARK_VERSION}\"\nENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\"\nENV PATH=\"$PATH:${SPARK_HOME}/bin\"\nRUN curl -sL --retry 3 \"https://www.apache.org/dyn/mirrors/mirrors.cgi?action=download&filename=spark/spark-${SPARK_VERSION}/${SPARK_PACKAGE}.tgz\" | gunzip | tar x -C /usr/ \\\n && mv /usr/$SPARK_PACKAGE $SPARK_HOME \\\n && chown -R root:root $SPARK_HOME\n#  # Use Debian unstable via pinning -- new style via APT::Default-Release\nRUN echo \"deb http://http.debian.net/debian sid main\" > /etc/apt/sources.list.d/debian-unstable.list \\\n && echo 'APT::Default-Release \"testing\";' > /etc/apt/apt.conf.d/default\nENV R_BASE_VERSION=\"3.5.3\"\n#  # Now install R and littler, and create a link for littler in /usr/local/bin\n#  # Also set a default CRAN repo, and make sure littler knows about it too\nRUN apt-get update \\\n && apt-get install --no-install-recommends unstable littler=0.3.1-1 r-cran-littler=0.3.1-1 r-base=${R_BASE_VERSION}* r-base-dev=${R_BASE_VERSION}* r-recommended=${R_BASE_VERSION}* -t -y \\\n && echo 'options(repos = c(CRAN = \"https://cran.rstudio.com/\"), download.file.method = \"libcurl\")' >> /etc/R/Rprofile.site \\\n && echo 'source(\"/etc/R/Rprofile.site\")' >> /etc/littler.r \\\n && ln -s /usr/share/doc/littler/examples/install.r /usr/local/bin/install.r \\\n && ln -s /usr/share/doc/littler/examples/install2.r /usr/local/bin/install2.r \\\n && ln -s /usr/share/doc/littler/examples/installGithub.r /usr/local/bin/installGithub.r \\\n && ln -s /usr/share/doc/littler/examples/testInstalled.r /usr/local/bin/testInstalled.r \\\n && install.r docopt \\\n && rm -rf /tmp/downloaded_packages/ /tmp/*.rds \\\n && rm -rf /var/lib/apt/lists/*\n#  RUN rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n#  RUN yum -y install R\nWORKDIR $SPARK_HOME\nCMD [\"bin/spark-class\", \"org.apache.spark.deploy.master.Master\"]\n#  RUN mkdir /scripts\n#  ADD start.sh /scripts/start.sh\n#  CMD [\"/scripts/start.sh\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM debian:stretch\nMAINTAINER Jim Harner <ejharner@gmail.com>\nARG hadoopversion=2.9.1\nARG sparkversion=2.4.3\nARG hiveversion=2.1.1\nRUN apt-get update \\\n && apt-get install locales -y \\\n && dpkg-reconfigure -f noninteractive locales \\\n && locale-gen C.UTF-8 \\\n && /usr/sbin/update-locale LANG=C.UTF-8 \\\n && echo \"en_US.UTF-8 UTF-8\" >> /etc/locale.gen \\\n && locale-gen \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#  Users with other locales should set this in their derivative image\nENV LANG=\"en_US.UTF-8\"\nENV LANGUAGE=\"en_US:en\"\nENV LC_ALL=\"en_US.UTF-8\"\nRUN apt-get update \\\n && apt-get install curl unzip python3 python3-setuptools -y \\\n && ln -s /usr/bin/python3 /usr/bin/python \\\n && easy_install3 pip py4j \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#  http://blog.stuart.axelbrooke.com/python-3-on-spark-return-of-the-pythonhashseed\nENV PYTHONHASHSEED=\"0\"\nENV PYTHONIOENCODING=\"UTF-8\"\nENV PIP_DISABLE_PIP_VERSION_CHECK=\"1\"\n#  JAVA\nARG JAVA_MAJOR_VERSION=8\nARG JAVA_UPDATE_VERSION=131\nARG JAVA_BUILD_NUMBER=11\nENV JAVA_HOME=\"/usr/jdk1.${JAVA_MAJOR_VERSION}.0_${JAVA_UPDATE_VERSION}\"\nENV PATH=\"$PATH:$JAVA_HOME/bin\"\nRUN curl -sL --retry 3 --insecure --header \"Cookie: oraclelicense=accept-securebackup-cookie;\" \"http://download.oracle.com/otn-pub/java/jdk/${JAVA_MAJOR_VERSION}u${JAVA_UPDATE_VERSION}-b${JAVA_BUILD_NUMBER}/d54c1d3a095b4ff2b6607d096fa80163/server-jre-${JAVA_MAJOR_VERSION}u${JAVA_UPDATE_VERSION}-linux-x64.tar.gz\" | gunzip | tar x -C /usr/ \\\n && ln -s $JAVA_HOME /usr/java \\\n && rm -rf $JAVA_HOME/man\n# ###################\n#  HADOOP\n# ###################\nENV HADOOP_VERSION=\"2.9.1\"\nENV HADOOP_HOME=\"/usr/hadoop-$HADOOP_VERSION\"\nENV HADOOP_CONF_DIR=\"$HADOOP_HOME/etc/hadoop\"\nENV PATH=\"$PATH:$HADOOP_HOME/bin\"\nRUN curl -sL --retry 3 \"http://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz\" | gunzip | tar -x -C /usr/ \\\n && rm -rf $HADOOP_HOME/share/doc \\\n && chown -R root:root $HADOOP_HOME\n#  SPARK\nENV SPARK_VERSION=\"2.4.3\"\nENV SPARK_PACKAGE=\"spark-${SPARK_VERSION}-bin-without-hadoop\"\nENV SPARK_HOME=\"/usr/spark-${SPARK_VERSION}\"\nENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\"\nENV PATH=\"$PATH:${SPARK_HOME}/bin\"\nRUN curl -sL --retry 3 \"https://www.apache.org/dyn/mirrors/mirrors.cgi?action=download&filename=spark/spark-${SPARK_VERSION}/${SPARK_PACKAGE}.tgz\" | gunzip | tar x -C /usr/ \\\n && mv /usr/$SPARK_PACKAGE $SPARK_HOME \\\n && chown -R root:root $SPARK_HOME\n# # Use Debian unstable via pinning -- new style via APT::Default-Release\nRUN echo \"deb http://http.debian.net/debian sid main\" > /etc/apt/sources.list.d/debian-unstable.list \\\n && echo 'APT::Default-Release \"testing\";' > /etc/apt/apt.conf.d/default\nENV R_BASE_VERSION=\"3.5.3\"\n# # Now install R and littler, and create a link for littler in /usr/local/bin\n# # Also set a default CRAN repo, and make sure littler knows about it too\nRUN apt-get update \\\n && apt-get install --no-install-recommends unstable littler r-cran-littler r-base=${R_BASE_VERSION}* r-base-dev=${R_BASE_VERSION}* r-recommended=${R_BASE_VERSION}* -t -y \\\n && echo 'options(repos = c(CRAN = \"https://cran.rstudio.com/\"), download.file.method = \"libcurl\")' >> /etc/R/Rprofile.site \\\n && echo 'source(\"/etc/R/Rprofile.site\")' >> /etc/littler.r \\\n && ln -s /usr/share/doc/littler/examples/install.r /usr/local/bin/install.r \\\n && ln -s /usr/share/doc/littler/examples/install2.r /usr/local/bin/install2.r \\\n && ln -s /usr/share/doc/littler/examples/installGithub.r /usr/local/bin/installGithub.r \\\n && ln -s /usr/share/doc/littler/examples/testInstalled.r /usr/local/bin/testInstalled.r \\\n && install.r docopt \\\n && rm -rf /tmp/downloaded_packages/ /tmp/*.rds \\\n && rm -rf /var/lib/apt/lists/*\n# RUN rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n# RUN yum -y install R\nWORKDIR $SPARK_HOME\nCMD [\"bin/spark-class\", \"org.apache.spark.deploy.master.Master\"]\n# RUN mkdir /scripts\n# ADD start.sh /scripts/start.sh\n# CMD [\"/scripts/start.sh\"]\n","injectedSmells":[],"originalDockerfileHash":"b9746a1b281cbcb1fe0b71d6e8ae71fe","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM debian:stretch\nMAINTAINER Jim Harner <ejharner@gmail.com>\nARG hadoopversion=2.9.1\nARG sparkversion=2.4.3\nARG hiveversion=2.1.1\nRUN apt-get update \\\n && apt-get install locales -y \\\n && dpkg-reconfigure -f noninteractive locales \\\n && locale-gen C.UTF-8 \\\n && /usr/sbin/update-locale LANG=C.UTF-8 \\\n && echo \"en_US.UTF-8 UTF-8\" >> /etc/locale.gen \\\n && locale-gen \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   Users with other locales should set this in their derivative image\nENV LANG=\"en_US.UTF-8\"\nENV LANGUAGE=\"en_US:en\"\nENV LC_ALL=\"en_US.UTF-8\"\nRUN apt-get update \\\n && apt-get install curl unzip python3 python3-setuptools -y \\\n && ln -s /usr/bin/python3 /usr/bin/python \\\n && easy_install3 pip py4j \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   http://blog.stuart.axelbrooke.com/python-3-on-spark-return-of-the-pythonhashseed\nENV PYTHONHASHSEED=\"0\"\nENV PYTHONIOENCODING=\"UTF-8\"\nENV PIP_DISABLE_PIP_VERSION_CHECK=\"1\"\n#   JAVA\nARG JAVA_MAJOR_VERSION=8\nARG JAVA_UPDATE_VERSION=131\nARG JAVA_BUILD_NUMBER=11\nENV JAVA_HOME=\"/usr/jdk1.${JAVA_MAJOR_VERSION}.0_${JAVA_UPDATE_VERSION}\"\nENV PATH=\"$PATH:$JAVA_HOME/bin\"\nRUN curl -sL --retry 3 --insecure --header \"Cookie: oraclelicense=accept-securebackup-cookie;\" \"http://download.oracle.com/otn-pub/java/jdk/${JAVA_MAJOR_VERSION}u${JAVA_UPDATE_VERSION}-b${JAVA_BUILD_NUMBER}/d54c1d3a095b4ff2b6607d096fa80163/server-jre-${JAVA_MAJOR_VERSION}u${JAVA_UPDATE_VERSION}-linux-x64.tar.gz\" | gunzip | tar x -C /usr/ \\\n && ln -s $JAVA_HOME /usr/java \\\n && rm -rf $JAVA_HOME/man\n#  ###################\n#   HADOOP\n#  ###################\nENV HADOOP_VERSION=\"2.9.1\"\nENV HADOOP_HOME=\"/usr/hadoop-$HADOOP_VERSION\"\nENV HADOOP_CONF_DIR=\"$HADOOP_HOME/etc/hadoop\"\nENV PATH=\"$PATH:$HADOOP_HOME/bin\"\nRUN curl -sL --retry 3 \"http://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz\" | gunzip | tar -x -C /usr/ \\\n && rm -rf $HADOOP_HOME/share/doc \\\n && chown -R root:root $HADOOP_HOME\n#   SPARK\nENV SPARK_VERSION=\"2.4.3\"\nENV SPARK_PACKAGE=\"spark-${SPARK_VERSION}-bin-without-hadoop\"\nENV SPARK_HOME=\"/usr/spark-${SPARK_VERSION}\"\nENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\"\nENV PATH=\"$PATH:${SPARK_HOME}/bin\"\nRUN curl -sL --retry 3 \"https://www.apache.org/dyn/mirrors/mirrors.cgi?action=download&filename=spark/spark-${SPARK_VERSION}/${SPARK_PACKAGE}.tgz\" | gunzip | tar x -C /usr/ \\\n && mv /usr/$SPARK_PACKAGE $SPARK_HOME \\\n && chown -R root:root $SPARK_HOME\n#  # Use Debian unstable via pinning -- new style via APT::Default-Release\nRUN echo \"deb http://http.debian.net/debian sid main\" > /etc/apt/sources.list.d/debian-unstable.list \\\n && echo 'APT::Default-Release \"testing\";' > /etc/apt/apt.conf.d/default\nENV R_BASE_VERSION=\"3.5.3\"\n#  # Now install R and littler, and create a link for littler in /usr/local/bin\n#  # Also set a default CRAN repo, and make sure littler knows about it too\nRUN apt-get update \\\n && apt-get install --no-install-recommends unstable littler r-cran-littler r-base=${R_BASE_VERSION}* r-base-dev=${R_BASE_VERSION}* r-recommended=${R_BASE_VERSION}* -t -y \\\n && echo 'options(repos = c(CRAN = \"https://cran.rstudio.com/\"), download.file.method = \"libcurl\")' >> /etc/R/Rprofile.site \\\n && echo 'source(\"/etc/R/Rprofile.site\")' >> /etc/littler.r \\\n && ln -s /usr/share/doc/littler/examples/install.r /usr/local/bin/install.r \\\n && ln -s /usr/share/doc/littler/examples/install2.r /usr/local/bin/install2.r \\\n && ln -s /usr/share/doc/littler/examples/installGithub.r /usr/local/bin/installGithub.r \\\n && ln -s /usr/share/doc/littler/examples/testInstalled.r /usr/local/bin/testInstalled.r \\\n && install.r docopt \\\n && rm -rf /tmp/downloaded_packages/ /tmp/*.rds \\\n && rm -rf /var/lib/apt/lists/*\n#  RUN rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\n#  RUN yum -y install R\nWORKDIR $SPARK_HOME\nCMD [\"bin/spark-class\", \"org.apache.spark.deploy.master.Master\"]\n#  RUN mkdir /scripts\n#  ADD start.sh /scripts/start.sh\n#  CMD [\"/scripts/start.sh\"]\n","originalDockerfileUglifiedHash":"958165367520735e9cb3084b1b3f392d","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/74185c8f216bbb68eaa8f0bff6bcc90dcf3550dd.dockerfile"}